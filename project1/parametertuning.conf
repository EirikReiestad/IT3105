[DEFAULT]
# min layers, max layers, min neurons, max neurons
hidden_layers=[1, 5, 1, 10]
# Activation function used for each layer of the neural network. Specify Sigmoid (0), Tanh (1) or RELU (2).
# Make sure it has the same length as the hidden_layers list.
activation_func = [[0, 0, 0, 0, 0], [1, 1, 1, 1, 1]]
# min, max, iterations
epochs = [5, 10, 2]
# min, max, iterations 
sim_timesteps = [10, 100, 50]
# min, max, iterations
learning_rate = [0.01, 0.3, 20]
