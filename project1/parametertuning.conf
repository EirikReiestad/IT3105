[DEFAULT]
# max layers, min layers, min neurons, max neurons
hidden_layers=[1, 2, 1, 2]
# Activation function used for each layer of the neural network. Specify Sigmoid (0), Tanh (1) or RELU (2).
activation_func = [0]
# min, max, iterations
epochs = [5, 10, 2]
# min, max, iterations 
sim_timesteps = [10, 50, 2]
# min, max, iterations
learning_rate = [0.01, 0.3, 2]
