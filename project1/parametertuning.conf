[DEFAULT]
# min layers, max layers, min neurons, max neurons
hidden_layers=[1, 5, 1, 10]
# Activation function used for each layer of the neural network. Specify Sigmoid (0), Tanh (1) or RELU (2).
activation_func = [0, 2, 3]
# min, max, iterations
epochs = [5, 10, 5]
# min, max, iterations 
sim_timesteps = [10, 100, 50]
# min, max, iterations
learning_rate = [0.01, 0.3, 20]
