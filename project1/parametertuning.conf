[DEFAULT]
# min layers, max layers, min neurons, max neurons
hidden_layers=[1, 5, 1, 10]
# Activation function used for each layer of the neural network. Specify Sigmoid (0), Tanh (1) or RELU (2).
activation_func = [0, 1, 2]
# min, max, iterations
epochs = [5, 10, 2]
# min, max, iterations 
sim_timesteps = [10, 100, 2]
# min, max, iterations
learning_rate = [0.01, 0.3, 2]
