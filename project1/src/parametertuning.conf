[DEFAULT]
hidden_layers = {
    min=1,
    max=5,
    min_num_neurons=1,
    max_num_neurons=10,
}
# Activation function used for each layer of the neural network. Specify Sigmoid (0), Tanh (1) or RELU (2).
activation_func = [0, 1, 2]
epochs = {
    min=10,
    max=30,
    iterations=10,
}
# min, max, num steps
sim_timesteps = {
    min=100,
    max=500,
    iterations=10,
}
learning_rate = {
    min=0.01,
    max=0.3,
    iterations=10,
}